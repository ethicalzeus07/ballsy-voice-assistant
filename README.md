### ğŸ¤ Ballsy Voice Assistant

Fullâ€‘stack AI voice assistant with a Siriâ€‘like UI, powered by Mistral AI â€” witty, confident, and psychologically grounded. Not just an assistant, Ballsy is a friend: playfully roasts you, listens, and gives honest, useful advice after real backâ€‘andâ€‘forth. Speak or type for concise, contextâ€‘aware answers and actionâ€‘ready commands (open sites, maps, media) in a slick animated interface.

![Python 3.8+](https://img.shields.io/badge/Python-3.8%2B-blue?logo=python)
![FastAPI](https://img.shields.io/badge/FastAPI-0.100%2B-009688?logo=fastapi)
![Mistral AI](https://img.shields.io/badge/Mistral%20AI-enabled-6f42c1)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)
![PRs welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?logo=git)
![Made with Love](https://img.shields.io/badge/made%20with-â¤ï¸-ff69b4)

### âœ¨ Features

- **Voice recognition**: Oneâ€‘shot browser speech recognition with realâ€‘time UI states
- **AI answers**: Mistral AI for concise, contextâ€‘aware responses
- **Smart commands**: Search the web, open services (YouTube, Netflix, Spotify), maps/directions, news
- **Math**: Inline calculations and chained operations (e.g., + 10)
- **WebSocket + REST**: Realâ€‘time updates and HTTP fallbacks
- **Siriâ€‘like UI**: Animated orb, typing indicator, dark mode

### ğŸ¤˜ Why Ballsy feels different

- **Friendâ€‘first persona**: More than a tool â€” Ballsy teases and motivates (light roasting), actually listens, and offers genuine, practical advice as the conversation unfolds.
- **Crafted voice**: Witty, confident, and psychologically grounded (think Ryan Reynoldsâ€™ delivery with Robert Greeneâ€™s clarity). Replies feel human, helpful, and entertaining â€” not generic.
- **Contextâ€‘aware by design**: Each request includes recent conversation turns, so Ballsy remembers the thread (within a server session) and stays in character.
- **Concise on purpose**: Defaults to singleâ€‘sentence, highâ€‘signal answers for speed and clarity; expands only when needed.
- **Actionâ€‘first responses**: Recognized intents (YouTube, Spotify, Maps, news, etc.) return actions (`open_url`, `search`) so the UI can do things immediately, not just talk.
- **Grounded honesty**: When uncertain, it deliberately falls back to helpful searches instead of guessing.

Model: `mistral-large-latest`.

### ğŸš€ Quick start

Prerequisites:
- Python 3.8+
- Microphone access + Internet
- `MISTRAL_API_KEY`

1) Clone and enter the project
```bash
git clone <your_repo_url>
cd ballsy-voice-assistant-main
```

2) Create a virtual environment
```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

3) Install dependencies
```bash
pip install -U fastapi uvicorn[standard] flask python-dotenv mistralai SpeechRecognition pydantic python-multipart websockets jinja2
```

4) Configure your API key
```bash
echo "MISTRAL_API_KEY=your_mistral_api_key_here" > .env
```

5) Run the app
```bash
python run.py
# then open http://localhost:8000
```

Dev reload (alternative):
```bash
uvicorn src.backend.app:app --host 0.0.0.0 --port 8000 --reload
```

### ğŸ—ï¸ Architecture overview

- **Backend (FastAPI)**: REST + WebSocket, SQLite persistence (`voice_assistant.db`), Mistral AI integration
- **Frontend (HTML/CSS/JS)**: Served by FastAPI; animated orb, chat history, dark mode
- **Key files**:
  - `src/backend/app.py` â€” API, WebSocket, command engine, DB
  - `src/frontend/templates/index.html` â€” main UI
  - `src/frontend/static/js/{voice.js, app.js, ui.js}` â€” voice, app logic, UI events

### ğŸ® Using Ballsy

- Click the orb to start/stop listening, or type in the input
- Examples:
  - â€œWho is Marie Curie?â€
  - â€œ5 + 10â€ then â€œ+ 3â€
  - â€œOpen YouTubeâ€ / â€œPlay Interstellar soundtrack on Spotifyâ€
  - â€œDirections to Central Parkâ€ / â€œFind cafes on Mapsâ€

Note: As a web app, native desktop apps cannot be opened; links open in your browser.

### ğŸ”Œ API

- `POST /api/command` â€” process text commands
- `POST /api/voice` â€” process uploaded audio (WAV)
- `GET /api/settings/{user_id}` â€” read settings
- `PUT /api/settings/{user_id}` â€” update settings
- `GET /api/history/{user_id}?limit=10` â€” recent command history
- `WS /ws/voice/{client_id}` â€” realâ€‘time command channel

Env vars:
```env
MISTRAL_API_KEY=your_mistral_api_key_here
# Optional
HOST=0.0.0.0
PORT=8000
```

### ğŸ§ª Testing (manual)

- Verify mic permissions and speak a few commands
- Try math, search, maps, and media commands
- Toggle dark mode; check WebSocket live responses

### ğŸ³ Docker (optional)

```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY . .
RUN pip install -U fastapi uvicorn[standard] flask python-dotenv mistralai SpeechRecognition pydantic python-multipart websockets jinja2
EXPOSE 8000
ENV PORT=8000
CMD ["python", "run.py"]
```

### ğŸ”’ Security & notes

- Keep `MISTRAL_API_KEY` in `.env` or your platformâ€™s secrets
- SQLite file is local; do not commit it
- CORS is open by default for local/dev; restrict in production

### ğŸ™ Credits

- Mistral AI, FastAPI, SpeechRecognition, Jinja2, and the openâ€‘source community

### ğŸ§© Sticker board

Add some flair to your issues/PRs and screenshots:

- Core vibe: ğŸ¤ğŸ§ âœ¨ğŸš€ğŸŒ™ğŸ’¬
- UI/voice: ğŸ”ŠğŸ›ï¸ğŸŸ£ğŸ”µğŸŸ¢ğŸŸ 
- Web/search: ğŸŒğŸ”ğŸ—ºï¸ğŸ§­
- Fun: ğŸ¦¾ğŸ”¥ğŸ•¶ï¸ğŸ’¥

Copyâ€‘paste packs:

- Starter: `ğŸ¤ ğŸ§  âœ¨`
- Power: `ğŸ¤ ğŸ§  âœ¨ ğŸš€ ğŸŒ ğŸ”`
- Night mode: `ğŸŒ™ ğŸ¤ ğŸŸ£ ğŸ’¬`

â€” Made with â¤ï¸ by Pravar Chauhan

Ballsy â€” your witty, wise AI companion
